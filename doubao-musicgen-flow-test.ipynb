{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install soundfile\n",
    "# !pip install av\n",
    "# !pip install julius\n",
    "# !pip install torchaudio\n",
    "# !pip install omegaconf\n",
    "# !pip install ipywidgets\n",
    "# !pip install openai\n",
    "# !pip install --upgrade typing-extensions\n",
    "# !pip install einops\n",
    "# !pip install xformers\n",
    "\n",
    "# !pip install --upgrade soundfile\n",
    "# !pip install -r requirements.txt\n",
    "# !pip install --upgrade pip setuptools wheel\n",
    "# !pip install flashy\n",
    "# !pip install num2words \n",
    "# !pip install spacy\n",
    "# !pip install transformers \n",
    "# !pip install librosa\n",
    "# !pip install torchmetrics\n",
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MusicGen\n",
    "Welcome to MusicGen's demo jupyter notebook. Here you will find a series of self-contained examples of how to use MusicGen in different settings.\n",
    "\n",
    "First, we start by initializing MusicGen, you can choose a model from the following selection:\n",
    "1. `facebook/musicgen-small` - 300M transformer decoder.\n",
    "2. `facebook/musicgen-medium` - 1.5B transformer decoder.\n",
    "3. `facebook/musicgen-melody` - 1.5B transformer decoder also supporting melody conditioning.\n",
    "4. `facebook/musicgen-large` - 3.3B transformer decoder.\n",
    "\n",
    "We will use the `facebook/musicgen-small` variant for the purpose of this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.6.0+cu124 with CUDA 1204 (you have 2.6.0+cpu)\n",
      "    Python  3.9.13 (you have 3.9.21)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "D:\\26371\\anaconda3\\envs\\AudioCraft\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.models import MultiBandDiffusion\n",
    "\n",
    "USE_DIFFUSION_DECODER = False\n",
    "# Using small model, better results would be obtained with `medium` or `large`.\n",
    "model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
    "if USE_DIFFUSION_DECODER:\n",
    "    mbd = MultiBandDiffusion.get_mbd_musicgen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us configure the generation parameters. Specifically, you can control the following:\n",
    "* `use_sampling` (bool, optional): use sampling if True, else do argmax decoding. Defaults to True.\n",
    "* `top_k` (int, optional): top_k used for sampling. Defaults to 250.\n",
    "* `top_p` (float, optional): top_p used for sampling, when set to 0 top_k is used. Defaults to 0.0.\n",
    "* `temperature` (float, optional): softmax temperature parameter. Defaults to 1.0.\n",
    "* `duration` (float, optional): duration of the generated waveform. Defaults to 30.0.\n",
    "* `cfg_coef` (float, optional): coefficient used for classifier free guidance. Defaults to 3.0.\n",
    "\n",
    "When left unchanged, MusicGen will revert to its default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Set the generation parameters for MusicGen.\\n\\n        Args:\\n            use_sampling (bool, optional): Use sampling if True, else do argmax decoding. Defaults to True.\\n            top_k (int, optional): top_k used for sampling. Defaults to 250.\\n            top_p (float, optional): top_p used for sampling, when set to 0 top_k is used. Defaults to 0.0.\\n            temperature (float, optional): Softmax temperature parameter. Defaults to 1.0.\\n            duration (float, optional): Duration of the generated waveform. Defaults to 30.0.\\n            cfg_coef (float, optional): Coefficient used for classifier free guidance. Defaults to 3.0.\\n            cfg_coef_beta (float, optional): beta coefficient in double classifier free guidance.\\n                Should be only used for MusicGen melody if we want to push the text condition more than\\n                the audio conditioning. See paragraph 4.3 in https://arxiv.org/pdf/2407.12563 to understand\\n                double CFG.\\n            two_step_cfg (bool, optional): If True, performs 2 forward for Classifier Free Guidance,\\n                instead of batching together the two. This has some impact on how things\\n                are padded but seems to have little impact in practice.\\n            extend_stride: when doing extended generation (i.e. more than 30 seconds), by how much\\n                should we extend the audio each time. Larger values will mean less context is\\n                preserved, and shorter value will require extra computations.\\n        '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_generation_params(\n",
    "    use_sampling=True,\n",
    "    top_k=250,\n",
    "    duration=10\n",
    ")\n",
    "\"\"\"Set the generation parameters for MusicGen.\n",
    "\n",
    "        Args:\n",
    "            use_sampling (bool, optional): Use sampling if True, else do argmax decoding. Defaults to True.\n",
    "            top_k (int, optional): top_k used for sampling. Defaults to 250.\n",
    "            top_p (float, optional): top_p used for sampling, when set to 0 top_k is used. Defaults to 0.0.\n",
    "            temperature (float, optional): Softmax temperature parameter. Defaults to 1.0.\n",
    "            duration (float, optional): Duration of the generated waveform. Defaults to 30.0.\n",
    "            cfg_coef (float, optional): Coefficient used for classifier free guidance. Defaults to 3.0.\n",
    "            cfg_coef_beta (float, optional): beta coefficient in double classifier free guidance.\n",
    "                Should be only used for MusicGen melody if we want to push the text condition more than\n",
    "                the audio conditioning. See paragraph 4.3 in https://arxiv.org/pdf/2407.12563 to understand\n",
    "                double CFG.\n",
    "            two_step_cfg (bool, optional): If True, performs 2 forward for Classifier Free Guidance,\n",
    "                instead of batching together the two. This has some impact on how things\n",
    "                are padded but seems to have little impact in practice.\n",
    "            extend_stride: when doing extended generation (i.e. more than 30 seconds), by how much\n",
    "                should we extend the audio each time. Larger values will mean less context is\n",
    "                preserved, and shorter value will require extra computations.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can go ahead and start generating music using one of the following modes:\n",
    "* Unconditional samples using `model.generate_unconditional`\n",
    "* Music continuation using `model.generate_continuation`\n",
    "* Text-conditional samples using `model.generate`\n",
    "* Melody-conditional samples using `model.generate_with_chroma`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music Continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torchaudio\n",
    "import torch\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "\n",
    "# def get_bip_bip(bip_duration=0.125, frequency=440,\n",
    "#                 duration=0.5, sample_rate=32000, device=\"cpu\"):\n",
    "#     \"\"\"Generates a series of bip bip at the given frequency.\"\"\"\n",
    "#     t = torch.arange(\n",
    "#         int(duration * sample_rate), device=\"cpu\", dtype=torch.float) / sample_rate\n",
    "#     wav = torch.cos(2 * math.pi * 440 * t)[None]\n",
    "#     tp = (t % (2 * bip_duration)) / (2 * bip_duration)\n",
    "#     envelope = (tp >= 0.5).float()\n",
    "#     return wav * envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Here we use a synthetic signal to prompt both the tonality and the BPM\n",
    "# # of the generated audio.\n",
    "# res = model.generate_continuation(\n",
    "#     get_bip_bip(0.125).expand(2, -1, -1), \n",
    "#     32000, ['Jazz jazz and only jazz', \n",
    "#             'Heartful EDM with beautiful synths and chords'], \n",
    "#     progress=True)\n",
    "# display_audio(res, 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can also use any audio from a file. Make sure to trim the file if it is too long!\n",
    "# prompt_waveform, prompt_sr = torchaudio.load(\"../assets/bach.mp3\")\n",
    "# prompt_duration = 2\n",
    "# prompt_waveform = prompt_waveform[..., :int(prompt_duration * prompt_sr)]\n",
    "# output = model.generate_continuation(prompt_waveform, prompt_sample_rate=prompt_sr, progress=True, return_tokens=True)\n",
    "# display_audio(output[0], sample_rate=32000)\n",
    "# if USE_DIFFUSION_DECODER:\n",
    "#     out_diffusion = mbd.tokens_to_wav(output[1])\n",
    "#     display_audio(out_diffusion, sample_rate=32000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-conditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARK_API_KEY=\"9e5d6644-81ee-4360-baf1-db1816b2c344\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# 请确保 ARK_API_KEY 已经在环境变量或其他地方正确设置\n",
    "# ARK_API_KEY = os.getenv(\"ARK_API_KEY\")26\n",
    "if ARK_API_KEY is None:\n",
    "    print(\"请设置 ARK_API_KEY 环境变量以继续。\")\n",
    "    exit(1)\n",
    "\n",
    "# 初始化豆包API客户端\n",
    "client = OpenAI(\n",
    "    api_key=ARK_API_KEY,\n",
    "    base_url=\"https://ark.cn-beijing.volces.com/api/v3\",\n",
    ")\n",
    "\n",
    "def create_music_prompt(user_input,api_key=ARK_API_KEY):\n",
    "    \"\"\"\n",
    "    接收用户输入，调用 API 生成仅包含音乐提示词的简短英文 prompt。\n",
    "    \"\"\"\n",
    "    if api_key is None:\n",
    "        print(\"请设置 api_key 环境变量以继续。\")\n",
    "    exit(1)\n",
    "\n",
    "    # 初始化豆包API客户端\n",
    "    client = OpenAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://ark.cn-beijing.volces.com/api/v3\",\n",
    "    )\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"ep-20250220214537-p7622\",  # 替换为实际使用的模型ID\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are a music prompt generator for a music generation model called 'musicgen'. \"\n",
    "                        \"Your task is to analyze the user's input, which may express a specific emotional state, \"\n",
    "                        \"and then generate a concise, clear, detailed, and creative English music prompt that \"\n",
    "                        \"incorporates elements to regulate or transform the stated emotion. For example, if the input \"\n",
    "                        \"indicates sadness, include musical elements that transition from melancholy to hope. If the input \"\n",
    "                        \"indicates anxiety, include calming, soothing elements to ease tension. Keep the output as short and clear as possible, \"\n",
    "                        \"without any extra commentary.\"\n",
    "                    )\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ])\n",
    "        final_prompt = completion.choices[0].message.content.strip()\n",
    "        return final_prompt\n",
    "    except Exception as e:\n",
    "        print(f\"Music prompt generation error: {e}\")\n",
    "        # 出现异常时返回一个默认的 prompt\n",
    "        return \"a gentle ambient piece with soft pads that gradually builds a sense of tranquility\"\n",
    "\n",
    "# def main():\n",
    "#     # 接受用户输入\n",
    "#     user_input = input(\"请输入情绪描述（例如：今天工作压力很大，需要放松）：\\n\")\n",
    "    \n",
    "#     # 生成适用于 musicgen 的英文提示词\n",
    "#     prompt = create_music_prompt(user_input)\n",
    "    \n",
    "#     # 格式化输出提示词（仅输出生成的 prompt）\n",
    "#     print(\"\\n\" + prompt)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_input=input(\"请输入情绪描述（例如：今天工作压力很大，需要放松）：\\n\")\n",
    "# prompt=create_music_prompt(user_input)\n",
    "# print(prompt)\n",
    "\n",
    "# from audiocraft.utils.notebook import display_audio\n",
    "\n",
    "# output = model.generate(\n",
    "#     descriptions=[\n",
    "#         prompt\n",
    "#     ],\n",
    "#     progress=True, return_tokens=True\n",
    "# )\n",
    "# display_audio(output[0], sample_rate=32000)\n",
    "# if USE_DIFFUSION_DECODER:\n",
    "#     out_diffusion = mbd.tokens_to_wav(output[1])\n",
    "#     display_audio(out_diffusion, sample_rate=32000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "事件已绑定\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    .widget-textarea {\n",
       "        width: 100%;\n",
       "    }\n",
       "    .widget-button {\n",
       "        margin: 10px 0;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ddef64858c48a5bcceaa323e874134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>情绪调节音乐生成器</h2>'), HTML(value='<hr>'), VBox(children=(Textarea(value='', descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "# 创建界面组件\n",
    "title = widgets.HTML(\n",
    "    value=\"<h2>情绪调节音乐生成器</h2>\"\n",
    ")\n",
    "\n",
    "input_text = widgets.Textarea(\n",
    "    placeholder='请输入情绪描述（例如：今天工作压力很大，需要放松）',\n",
    "    description='情绪描述:',\n",
    "    layout=widgets.Layout(width='90%', height='80px')\n",
    ")\n",
    "\n",
    "generate_button = widgets.Button(\n",
    "    description='开始生成',\n",
    "    button_style='primary',\n",
    "    icon='music'\n",
    ")\n",
    "\n",
    "debug_output = widgets.Output()  # 添加调试输出区域\n",
    "prompt_display = widgets.HTML(value=\"\")\n",
    "status_label = widgets.HTML(value=\"\")\n",
    "audio_output = widgets.Output()\n",
    "\n",
    "# 生成音乐的函数\n",
    "def generate_music(b):\n",
    "    # 先清除之前的输出\n",
    "    with debug_output:\n",
    "        clear_output()\n",
    "        print(\"按钮被点击，开始处理...\")\n",
    "    \n",
    "    status_label.value = \"正在处理...\"\n",
    "    \n",
    "    try:\n",
    "        # 获取用户输入\n",
    "        user_input = input_text.value\n",
    "        \n",
    "        with debug_output:\n",
    "            print(f\"用户输入: {user_input}\")\n",
    "        \n",
    "        # 验证模型是否已加载\n",
    "        if 'model' not in globals() or model is None:\n",
    "            status_label.value = \"<span style='color:red;'>错误: 模型未加载，请确保已运行加载模型的代码</span>\"\n",
    "            with debug_output:\n",
    "                print(\"错误：模型未加载\")\n",
    "            return\n",
    "        \n",
    "        # 调用已定义的函数生成提示词\n",
    "        prompt = create_music_prompt(user_input)\n",
    "        prompt_display.value = f\"<b>生成的提示词:</b> {prompt}\"\n",
    "        \n",
    "        with debug_output:\n",
    "            print(f\"生成的提示词: {prompt}\")\n",
    "            print(\"开始生成音乐...\")\n",
    "        \n",
    "        # 生成音乐\n",
    "        with audio_output:\n",
    "            clear_output()\n",
    "            output = model.generate(\n",
    "                descriptions=[prompt],\n",
    "                progress=True, return_tokens=True\n",
    "            )\n",
    "            \n",
    "            with debug_output:\n",
    "                print(\"音乐生成完成，显示音频...\")\n",
    "            \n",
    "            # 显示生成的音乐\n",
    "            display_audio(output[0], sample_rate=32000)\n",
    "            \n",
    "            # 如果使用扩散解码器\n",
    "            if 'USE_DIFFUSION_DECODER' in globals() and USE_DIFFUSION_DECODER:\n",
    "                if 'mbd' in globals() and mbd is not None:\n",
    "                    out_diffusion = mbd.tokens_to_wav(output[1])\n",
    "                    display_audio(out_diffusion, sample_rate=32000)\n",
    "                \n",
    "        status_label.value = \"音乐生成完成！\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        # 捕获并显示详细错误信息\n",
    "        error_details = traceback.format_exc()\n",
    "        status_label.value = f\"<span style='color:red;'>生成过程中出错: {str(e)}</span>\"\n",
    "        \n",
    "        with debug_output:\n",
    "            print(\"发生错误:\")\n",
    "            print(error_details)\n",
    "\n",
    "# 确保清晰地绑定事件\n",
    "generate_button.on_click(generate_music)\n",
    "print(\"事件已绑定\")  # 确认事件绑定\n",
    "\n",
    "# 布局所有组件\n",
    "input_box = widgets.VBox([input_text, generate_button])\n",
    "output_box = widgets.VBox([status_label, prompt_display, audio_output, debug_output])\n",
    "\n",
    "# 显示整个界面\n",
    "main_layout = widgets.VBox([\n",
    "    title,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    input_box,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    output_box\n",
    "])\n",
    "\n",
    "# 添加一些简单的样式\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "    .widget-textarea {\n",
    "        width: 100%;\n",
    "    }\n",
    "    .widget-button {\n",
    "        margin: 10px 0;\n",
    "    }\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "display(main_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import soundfile as sf  # 需要安装soundfile库\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试用例集合\n",
    "test_cases = [\n",
    "    # 悲伤/抑郁系列\n",
    "    # {\n",
    "    #     \"case_name\": \"depression_case_1\",\n",
    "    #     \"input\": \"持续三个月的抑郁状态，感觉生活失去色彩\",\n",
    "    #     \"expected_params\": {\"emotion\": \"悲伤\", \"valence\": 2, \"arousal\": 3}\n",
    "    # # },\n",
    "    # {\n",
    "    #     \"case_name\": \"depression_case_2\",\n",
    "    #     \"input\": \"阴沉的天气与内心的孤独，让我陷入深深的抑郁\",\n",
    "    #     \"expected_params\": {\"emotion\": \"悲伤\", \"valence\": 2, \"arousal\": 3}\n",
    "    # },\n",
    "    # {\n",
    "    #     \"case_name\": \"depression_case_3\",\n",
    "    #     \"input\": \"连续的失败和失望让我觉得世界一片黑暗\",\n",
    "    #     \"expected_params\": {\"emotion\": \"悲伤\", \"valence\": 2, \"arousal\": 3}\n",
    "    # },\n",
    "\n",
    "    # # 焦虑/恐惧系列\n",
    "    # {\n",
    "    #     \"case_name\": \"anxiety_case_1\",\n",
    "    #     \"input\": \"明天有重要演讲，心跳加速坐立不安\",\n",
    "    #     \"expected_params\": {\"emotion\": \"恐惧\", \"valence\": 4, \"arousal\": 8}\n",
    "    # },\n",
    "    # {\n",
    "    #     \"case_name\": \"anxiety_case_2\",\n",
    "    #     \"input\": \"对未来充满未知感，让我夜夜难以入眠\",\n",
    "    #     \"expected_params\": {\"emotion\": \"恐惧\", \"valence\": 4, \"arousal\": 8}\n",
    "    # },\n",
    "    # {\n",
    "    #     \"case_name\": \"anxiety_case_3\",\n",
    "    #     \"input\": \"在高压环境中，我不断感受到强烈的焦虑与紧张\",\n",
    "    #     \"expected_params\": {\"emotion\": \"恐惧\", \"valence\": 4, \"arousal\": 8}\n",
    "    # # },\n",
    "\n",
    "    # # 快乐系列\n",
    "    # {\n",
    "    #     \"case_name\": \"joyful_case_1\",\n",
    "    #     \"input\": \"收到梦想公司的offer，兴奋得睡不着觉\",\n",
    "    #     \"expected_params\": {\"emotion\": \"快乐\", \"valence\": 8, \"arousal\": 7}\n",
    "    # },\n",
    "    # {\n",
    "    #     \"case_name\": \"joyful_case_2\",\n",
    "    #     \"input\": \"今天得知了一个好消息，整个人都充满无限喜悦\",\n",
    "    #     \"expected_params\": {\"emotion\": \"快乐\", \"valence\": 8, \"arousal\": 7}\n",
    "    # },\n",
    "    # {\n",
    "    #     \"case_name\": \"joyful_case_3\",\n",
    "    #     \"input\": \"在阳光灿烂的日子里，我感觉心情如同飞扬的音符\",\n",
    "    #     \"expected_params\": {\"emotion\": \"快乐\", \"valence\": 8, \"arousal\": 7}\n",
    "    # },\n",
    "\n",
    "    # # 愤怒系列\n",
    "    # {\n",
    "    #     \"case_name\": \"anger_case_1\",\n",
    "    #     \"input\": \"遭遇背叛和不公正待遇，我内心充满了愤怒与不满\",\n",
    "    #     \"expected_params\": {\"emotion\": \"愤怒\", \"valence\": 3, \"arousal\": 8}\n",
    "    # },\n",
    "    # {\n",
    "    #     \"case_name\": \"anger_case_2\",\n",
    "    #     \"input\": \"在激烈争执中，我几乎无法控制内心的怒火\",\n",
    "    #     \"expected_params\": {\"emotion\": \"愤怒\", \"valence\": 3, \"arousal\": 8}\n",
    "    # },\n",
    "    # {\n",
    "    #     \"case_name\": \"anger_case_3\",\n",
    "    #     \"input\": \"面对持续的不正义，我的心中燃起了熊熊怒焰\",\n",
    "    #     \"expected_params\": {\"emotion\": \"愤怒\", \"valence\": 3, \"arousal\": 8}\n",
    "    # },\n",
    "\n",
    "    # # 平静系列\n",
    "    # {\n",
    "    #     \"case_name\": \"calm_case_1\",\n",
    "    #     \"input\": \"夜深人静时，我静静欣赏着窗外的月光，感受到内心的平静\",\n",
    "    #     \"expected_params\": {\"emotion\": \"平静\", \"valence\": 7, \"arousal\": 2}\n",
    "    # },\n",
    "    # {\n",
    "    #     \"case_name\": \"calm_case_2\",\n",
    "    #     \"input\": \"在湖边静坐，微风拂过，我感到无比的放松与安宁\",\n",
    "    #     \"expected_params\": {\"emotion\": \"平静\", \"valence\": 7, \"arousal\": 2}\n",
    "    # },\n",
    "    # {\n",
    "    #     \"case_name\": \"calm_case_3\",\n",
    "    #     \"input\": \"清晨的鸟鸣与柔和的阳光让我心情彻底平复\",\n",
    "    #     \"expected_params\": {\"emotion\": \"平静\", \"valence\": 7, \"arousal\": 2}\n",
    "    # },\n",
    "\n",
    "    # # 怀旧系列\n",
    "    # {\n",
    "    #     \"case_name\": \"nostalgic_case_1\",\n",
    "    #     \"input\": \"回忆起童年美好的时光，心中涌起淡淡的怀旧与温馨\",\n",
    "    #     \"expected_params\": {\"emotion\": \"怀旧\", \"valence\": 6, \"arousal\": 3}\n",
    "    # },\n",
    "    # {\n",
    "    #     \"case_name\": \"nostalgic_case_2\",\n",
    "    #     \"input\": \"翻看旧日照片，让我沉浸在温馨而久远的记忆中\",\n",
    "    #     \"expected_params\": {\"emotion\": \"怀旧\", \"valence\": 6, \"arousal\": 3}\n",
    "    # },\n",
    "    # {\n",
    "    #     \"case_name\": \"nostalgic_case_3\",\n",
    "    #     \"input\": \"悠扬的老歌唤起了我深藏心底的往日回忆\",\n",
    "    #     \"expected_params\": {\"emotion\": \"怀旧\", \"valence\": 6, \"arousal\": 3}\n",
    "    # },\n",
    "\n",
    "    # 希望系列\n",
    "    {\n",
    "        \"case_name\": \"hopeful_case_1\",\n",
    "        \"input\": \"经历了一连串挫折后，我依然对未来充满坚定的希望\",\n",
    "        \"expected_params\": {\"emotion\": \"希望\", \"valence\": 7, \"arousal\": 4}\n",
    "    },\n",
    "    {\n",
    "        \"case_name\": \"hopeful_case_2\",\n",
    "        \"input\": \"在逆境中，我看到了前方的一线光明\",\n",
    "        \"expected_params\": {\"emotion\": \"希望\", \"valence\": 7, \"arousal\": 4}\n",
    "    },\n",
    "    {\n",
    "        \"case_name\": \"hopeful_case_3\",\n",
    "        \"input\": \"尽管前路艰辛，我对明天依然满怀信心\",\n",
    "        \"expected_params\": {\"emotion\": \"希望\", \"valence\": 7, \"arousal\": 4}\n",
    "    },\n",
    "\n",
    "    # 困惑系列\n",
    "    {\n",
    "        \"case_name\": \"confused_case_1\",\n",
    "        \"input\": \"面对前路的未知和不确定性，我感到无比迷茫和困惑\",\n",
    "        \"expected_params\": {\"emotion\": \"困惑\", \"valence\": 4, \"arousal\": 5}\n",
    "    },\n",
    "    {\n",
    "        \"case_name\": \"confused_case_2\",\n",
    "        \"input\": \"在每个抉择点上，我都感到前所未有的迷失\",\n",
    "        \"expected_params\": {\"emotion\": \"困惑\", \"valence\": 4, \"arousal\": 5}\n",
    "    },\n",
    "    {\n",
    "        \"case_name\": \"confused_case_3\",\n",
    "        \"input\": \"站在人生的十字路口，我不知道该迈向哪个方向\",\n",
    "        \"expected_params\": {\"emotion\": \"困惑\", \"valence\": 4, \"arousal\": 5}\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# # 创建保存目录\n",
    "# output_dir = Path(\"./generated_music./250223\")\n",
    "# output_dir.mkdir(exist_ok=True)\n",
    "# for i in range(1):\n",
    "#     print(f'{i} set started.')\n",
    "#     # 修改后的生成逻辑\n",
    "#     for test_case in test_cases:\n",
    "#         try:\n",
    "#             # 生成时间戳\n",
    "#             timestamp = int(time.time())\n",
    "            \n",
    "#             # 生成prompt\n",
    "#             prompt = create_music_prompt(test_case[\"input\"])\n",
    "            \n",
    "#             # 保存prompt文本\n",
    "#             prompt_path = output_dir / f\"{test_case['case_name']}_{timestamp}.txt\"\n",
    "#             with open(prompt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#                 f.write(f\"Input: {test_case['input']}\\n\")\n",
    "#                 f.write(f\"Generated Prompt: {prompt}\\n\")\n",
    "#                 f.write(f\"Expected Params: {test_case['expected_params']}\")\n",
    "            \n",
    "#             # 生成音频\n",
    "#             output = model.generate(\n",
    "#                 descriptions=[prompt],\n",
    "#                 progress=True,  # 批量生成时关闭进度条\n",
    "#                 return_tokens=True\n",
    "#             )\n",
    "#             # 修改音频保存部分为：\n",
    "#             audio_data = output[0].cpu().numpy()\n",
    "            \n",
    "#             # 维度处理流程\n",
    "#             if audio_data.ndim == 3:  # 处理批次维度\n",
    "#                 audio_data = audio_data.squeeze(0)\n",
    "                \n",
    "#             if audio_data.ndim == 2 and audio_data.shape[0] < audio_data.shape[1]:\n",
    "#                 audio_data = audio_data.T  # 确保是(samples, channels)格式\n",
    "            \n",
    "#             # 振幅归一化（防止削波）\n",
    "#             audio_data = audio_data / np.max(np.abs(audio_data))\n",
    "#             # 保存音频文件（WAV格式）\n",
    "#             audio_path = output_dir / f\"{test_case['case_name']}_{timestamp}.wav\"\n",
    "#             sf.write(audio_path, \n",
    "#                     audio_data,\n",
    "#                     samplerate=32000)\n",
    "    \n",
    "            \n",
    "        \n",
    "#             # 可选：保存扩散解码器输出\n",
    "#             if USE_DIFFUSION_DECODER:\n",
    "#                 out_diffusion = mbd.tokens_to_wav(output[1])\n",
    "#                 diffusion_path = output_dir / f\"{test_case['case_name']}_diffusion_{timestamp}.wav\"\n",
    "#                 sf.write(diffusion_path, \n",
    "#                         out_diffusion.cpu().numpy(),\n",
    "#                         samplerate=32000)\n",
    "                \n",
    "#             print(f\"成功生成案例 [{test_case['case_name']}] 文件保存在 {audio_path}\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"案例 [{test_case['case_name']}] 生成失败: {str(e)}\")\n",
    "#             continue\n",
    "\n",
    "# print(\"所有测试用例处理完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### from audiocraft.utils.notebook import display_audio\n",
    "\n",
    "output = model.generate(\n",
    "    descriptions=[\n",
    "        #'80s pop track with bassy drums and synth',\n",
    "        #'90s rock song with loud guitars and heavy drums',\n",
    "        #'Progressive rock drum and bass solo',\n",
    "        'Punk Rock song with loud drum and power guitar',\n",
    "        #'Bluesy guitar instrumental with soulful licks and a driving rhythm section',\n",
    "        #'Jazz Funk song with slap bass and powerful saxophone',\n",
    "        # 'drum and bass beat with intense percussions'\n",
    "    ],\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "display_audio(output[0], sample_rate=32000)\n",
    "if USE_DIFFUSION_DECODER:\n",
    "    out_diffusion = mbd.tokens_to_wav(output[1])\n",
    "    display_audio(out_diffusion, sample_rate=32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 开始计时\n",
    "start_time = time.time()\n",
    "\n",
    "# 生成输出\n",
    "output = model.generate(\n",
    "    descriptions=[\n",
    "        'Progressive rock drum and bass solo',\n",
    "    ],\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "\n",
    "# 显示音频\n",
    "display_audio(output[0], sample_rate=32000)\n",
    "\n",
    "# 如果使用扩散解码器\n",
    "if USE_DIFFUSION_DECODER:\n",
    "    out_diffusion = mbd.tokens_to_wav(output[1])\n",
    "    display_audio(out_diffusion, sample_rate=32000)\n",
    "\n",
    "# 结束计时\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# 输出所需时间\n",
    "print(f\"所需时间: {elapsed_time:.2f} 秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melody-conditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "\n",
    "model = MusicGen.get_pretrained('facebook/musicgen-melody')\n",
    "model.set_generation_params(duration=8)\n",
    "\n",
    "melody_waveform, sr = torchaudio.load(\"../assets/bach.mp3\")\n",
    "melody_waveform = melody_waveform.unsqueeze(0).repeat(2, 1, 1)\n",
    "output = model.generate_with_chroma(\n",
    "    descriptions=[\n",
    "        '80s pop track with bassy drums and synth',\n",
    "        '90s rock song with loud guitars and heavy drums',\n",
    "    ],\n",
    "    melody_wavs=melody_waveform,\n",
    "    melody_sample_rate=sr,\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "display_audio(output[0], sample_rate=32000)\n",
    "if USE_DIFFUSION_DECODER:\n",
    "    out_diffusion = mbd.tokens_to_wav(output[1])\n",
    "    display_audio(out_diffusion, sample_rate=32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "vscode": {
   "interpreter": {
    "hash": "b02c911f9b3627d505ea4a19966a915ef21f28afb50dbf6b2115072d27c69103"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
